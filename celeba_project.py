# -*- coding: utf-8 -*-
"""CelebA_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ICGinrUpaPAihrkxbJCm73_qYgctVk6M

- De antrenat un face detector si de testat pe video-uri
- https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html
- https://www.kaggle.com/jessicali9530/celeba-dataset/download
- https://pytorch.org/tutorials/beginner/basics/data_tutorial.html

Smile detector   
Image Classification -> Supervised->Classification -> Binary Classification       
Folosim retea preantrenata si eliminam ultimele layere liniare, Data generator/ Data loader

###Imports
"""

import torch
import torchvision
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
import os
import pandas as pd
from torchvision.io import read_image
import torch.optim as optim
import torch.nn as nn
from PIL import Image
from torchvision.models import regnet_y_400mf

if torch.cuda.is_available(): 
  dev = "cuda:0" 
else: 
  dev = "cpu" 
device = torch.device(dev)

dev

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# import os

# os.path.isfile("/content/drive/MyDrive/Colab\ Notebooks/CelebA_Project/archive.zip")
# !unzip /content/drive/MyDrive/Colab\ Notebooks/CelebA_Project/archive.zip -d /content/drive/MyDrive/Colab\ Notebooks/CelebA_Project/

# img_dir = "/content/drive/MyDrive/Colab Notebooks/CelebA_Project/img_align_celeba/img_align_celeba"
# import os
# for ix, file in enumerate(os.listdir(img_dir)):
#     if ix > 5000:
#         os.remove(os.path.join(img_dir, file))

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/CelebA_Project/archive/list_attr_celeba.csv")

model = regnet_y_400mf(weights='IMAGENET1K_V1', )

print(model)

print(model.fc)

model.fc = torch.nn.Linear(in_features=440, out_features=2, bias=True)

print(model.fc)

model.to(device)

transform = torchvision.transforms.Compose([torchvision.transforms.Resize((128, 128)),
                                            torchvision.transforms.ToTensor()])

class CelebADataset(Dataset):
    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None, validation=False):
        self.img_labels = pd.read_csv(annotations_file)
        valid_images = os.listdir(img_dir) # imi iau imaginile din directorul din drive
        if validation == True:
            valid_images = valid_images[int(0.8*len(valid_images)):]
        else:
            valid_images = valid_images[:int(0.8*len(valid_images))]
        self.img_labels = self.img_labels[self.img_labels["image_id"].isin(valid_images)]# ca sa fie aceleasi imagini pe drive si in csv
        self.img_labels = self.img_labels.reset_index()
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.loc[idx, "image_id"]) # ia din image_id fiecare index pentru imagine
        image = Image.open(img_path)
        label = self.img_labels.loc[idx, "Smiling"]
        if label == -1:
            label = label + 1  # ca sa avem etichetele 0 si 1
            # label = 0
        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)
        return image, label

transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])

CelebA_dataset_train = CelebADataset(annotations_file="/content/drive/MyDrive/Colab Notebooks/CelebA_Project/archive/list_attr_celeba.csv",
                               img_dir="/content/drive/MyDrive/Colab Notebooks/CelebA_Project/archive/img_align_celeba/img_align_celeba", transform=transform, validation=False)
CelebA_dataset_validation = CelebADataset(annotations_file="/content/drive/MyDrive/Colab Notebooks/CelebA_Project/archive/list_attr_celeba.csv",
                               img_dir="/content/drive/MyDrive/Colab Notebooks/CelebA_Project/archive/img_align_celeba/img_align_celeba", transform=transform, validation=True)

from torch.utils.data import DataLoader

trainloader = DataLoader(CelebA_dataset_train, batch_size=64, shuffle=True, num_workers=4)
validloader = DataLoader(CelebA_dataset_validation, batch_size=64, shuffle=False, num_workers=4)

print(CelebA_dataset_train.__len__())

print(CelebA_dataset_train.__getitem__(7000))

trainloader

"""Inlocuirea ultimului layer din modelul importat"""

# presupunem ca am creat deja dataset-ul/dataloader-ul

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #(nesterov momentum)

# Train the network

from time import time
from tqdm import tqdm 

num_epochs = 20

checkpoint_dir = "/content/drive/MyDrive/Colab Notebooks/CelebA_Project/checkpoint_experiment1"
if os.path.isdir(checkpoint_dir) == False:
    os.makedirs(checkpoint_dir)

steps_to_checkpoint = 50

for epoch in range(num_epochs):  # loop over the dataset multiple times

    running_loss = 0.0
    model.train()

    for i, data in tqdm(enumerate(trainloader, 0)):
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)
        # zero the parameter gradients
        optimizer.zero_grad()
        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)        
        loss.backward()        
        optimizer.step()
        #end = time()
        #print("We spent ", end - start, "on fwd+bwd the data")
        # print statistics
        running_loss += loss.item()
        if i % 200 == 199:    # print every 200 mini-batches
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')
            running_loss = 0.0
        if i % steps_to_checkpoint == 49:
            torch.save(model.state_dict(), os.path.join(checkpoint_dir, "model_step_" + str(i) + "_epoch_" + str(epoch) + ".pth"))
        
    model.eval() # opresc orice actualizare de parametri
    running_loss = 0
    corrects = 0
    for j, data in tqdm(enumerate(validloader, 0)):
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
          outputs = model(inputs)
          prob_outputs = nn.Softmax(dim=-1)(outputs)
        predicted_labels = torch.argmax(prob_outputs, dim=1)
        loss = criterion(outputs, labels)
        running_loss += loss.item()
        corrects += torch.sum(predicted_labels == labels)
    print(f'[{epoch + 1}] loss: {running_loss / (j+1):.3f}')
    print("Accuracy is ", corrects / ((j+1)*64))

print('Finished Training')

"""Inferenta"""

checkpoint_model = "/content/drive/MyDrive/Colab Notebooks/CelebA_Project/checkpoint_experiment1/model_step_49_epoch_5.pth"

model = regnet_y_400mf(weights='IMAGENET1K_V1', )
model.fc = torch.nn.Linear(in_features=440, out_features=2, bias=True)
model.load_state_dict(torch.load(checkpoint_model))

model.eval()
model.to(device)
running_loss = 0
corrects = 0
    
for j, data in tqdm(enumerate(validloader, 0)):
    inputs, labels = data
    inputs = inputs.to(device)
    labels = labels.to(device)
    with torch.no_grad():
      outputs = model(inputs)
      prob_outputs = nn.Softmax(dim=-1)(outputs)
    predicted_labels = torch.argmax(prob_outputs, dim=1)
    loss = criterion(outputs, labels)
    running_loss += loss.item()
    corrects += torch.sum(predicted_labels == labels)
print(f'[{epoch + 1}] loss: {running_loss / (j+1):.3f}')
print("Accuracy is ", corrects / ((j+1)*64))

print('Finished Training')

