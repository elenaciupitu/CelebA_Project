{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zZRsMVjKFWJ"
      },
      "source": [
        "- De antrenat un face detector si de testat pe video-uri\n",
        "- https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n",
        "- https://www.kaggle.com/jessicali9530/celeba-dataset/download\n",
        "- https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "Smile detector   \n",
        "Image Classification -> Supervised->Classification -> Binary Classification       \n",
        "Folosim retea preantrenata si eliminam ultimele layere liniare, Data generator/ Data loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2TPEqiqbR19"
      },
      "source": [
        "###Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q1FK7tmZK9zw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision.models import regnet_y_400mf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): \n",
        "  dev = \"cuda:0\" \n",
        "else: \n",
        "  dev = \"cpu\" \n",
        "device = torch.device(dev)"
      ],
      "metadata": {
        "id": "hA-gXHwq9U0H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ewh8BE8s9exQ",
        "outputId": "481cea17-a81a-490a-b809-05b088065d22"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RVlXsZSoDgNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61536b41-c20e-44e5-aa25-4b70a7b90b0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRCQ6S6YHvdL"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.path.isfile(\"/content/drive/MyDrive/Colab\\ Notebooks/CelebA_Project/archive.zip\")\n",
        "# !unzip /content/drive/MyDrive/Colab\\ Notebooks/CelebA_Project/archive.zip -d /content/drive/MyDrive/Colab\\ Notebooks/CelebA_Project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULfticC1dfLh"
      },
      "outputs": [],
      "source": [
        "# img_dir = \"/content/drive/MyDrive/Colab Notebooks/CelebA_Project/img_align_celeba/img_align_celeba\"\n",
        "# import os\n",
        "# for ix, file in enumerate(os.listdir(img_dir)):\n",
        "#     if ix > 5000:\n",
        "#         os.remove(os.path.join(img_dir, file))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/CelebA_Project/archive/list_attr_celeba.csv\")"
      ],
      "metadata": {
        "id": "lWscC1W19ulT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = regnet_y_400mf(weights='IMAGENET1K_V1', )"
      ],
      "metadata": {
        "id": "imNrGvkD96nq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lNIyNQsanZBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1419f6a-f3e9-44f0-ec32-43a7c5a876aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RegNet(\n",
            "  (stem): SimpleStemIN(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (trunk_output): Sequential(\n",
            "    (block1): AnyStage(\n",
            "      (block1-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=6, bias=False)\n",
            "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block2): AnyStage(\n",
            "      (block2-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(48, 104, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(48, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(104, 104, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=13, bias=False)\n",
            "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(104, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(12, 104, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block2-1): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n",
            "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(104, 26, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(26, 104, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block2-2): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n",
            "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(104, 26, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(26, 104, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block3): AnyStage(\n",
            "      (block3-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(104, 208, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(104, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=26, bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(208, 26, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(26, 208, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-1): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-2): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-3): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-4): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-5): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block4): AnyStage(\n",
            "      (block4-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(208, 440, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(208, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=55, bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(440, 52, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(52, 440, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-1): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-2): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-3): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-4): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-5): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (se): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU()\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=440, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jTSlNrwkbk8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797b281a-b4ee-4d99-c4c9-35f6519cfaf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=440, out_features=1000, bias=True)\n"
          ]
        }
      ],
      "source": [
        "print(model.fc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Sl15yHRxbOK9"
      },
      "outputs": [],
      "source": [
        "model.fc = torch.nn.Linear(in_features=440, out_features=2, bias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R3MoA6D6g14E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6637eb6-f1d0-4036-eae8-f169045b7369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=440, out_features=2, bias=True)\n"
          ]
        }
      ],
      "source": [
        "print(model.fc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F4PrSXa_KxQ",
        "outputId": "3d0a967d-a0ef-4501-e553-57592fb9fab9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RegNet(\n",
              "  (stem): SimpleStemIN(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (trunk_output): Sequential(\n",
              "    (block1): AnyStage(\n",
              "      (block1-0): ResBottleneckBlock(\n",
              "        (proj): Conv2dNormActivation(\n",
              "          (0): Conv2d(32, 48, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=6, bias=False)\n",
              "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (block2): AnyStage(\n",
              "      (block2-0): ResBottleneckBlock(\n",
              "        (proj): Conv2dNormActivation(\n",
              "          (0): Conv2d(48, 104, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(48, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(104, 104, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=13, bias=False)\n",
              "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(104, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(12, 104, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block2-1): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n",
              "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(104, 26, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(26, 104, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block2-2): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n",
              "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(104, 26, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(26, 104, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(104, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (block3): AnyStage(\n",
              "      (block3-0): ResBottleneckBlock(\n",
              "        (proj): Conv2dNormActivation(\n",
              "          (0): Conv2d(104, 208, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(104, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=26, bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(208, 26, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(26, 208, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-1): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-2): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-3): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-4): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block3-5): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=26, bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(208, 52, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(52, 208, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (block4): AnyStage(\n",
              "      (block4-0): ResBottleneckBlock(\n",
              "        (proj): Conv2dNormActivation(\n",
              "          (0): Conv2d(208, 440, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(208, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=55, bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(440, 52, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(52, 440, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block4-1): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block4-2): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block4-3): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block4-4): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "      (block4-5): ResBottleneckBlock(\n",
              "        (f): BottleneckTransform(\n",
              "          (a): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (b): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(440, 110, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(110, 440, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (c): Conv2dNormActivation(\n",
              "            (0): Conv2d(440, 440, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (activation): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=440, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = torchvision.transforms.Compose([torchvision.transforms.Resize((128, 128)),\n",
        "                                            torchvision.transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "5uT2JRxV_JFx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "plr6QXA8BeeC"
      },
      "outputs": [],
      "source": [
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None, validation=False):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        valid_images = os.listdir(img_dir) # imi iau imaginile din directorul din drive\n",
        "        if validation == True:\n",
        "            valid_images = valid_images[int(0.8*len(valid_images)):]\n",
        "        else:\n",
        "            valid_images = valid_images[:int(0.8*len(valid_images))]\n",
        "        self.img_labels = self.img_labels[self.img_labels[\"image_id\"].isin(valid_images)]# ca sa fie aceleasi imagini pe drive si in csv\n",
        "        self.img_labels = self.img_labels.reset_index()\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.loc[idx, \"image_id\"]) # ia din image_id fiecare index pentru imagine\n",
        "        image = Image.open(img_path)\n",
        "        label = self.img_labels.loc[idx, \"Smiling\"]\n",
        "        if label == -1:\n",
        "            label = label + 1  # ca sa avem etichetele 0 si 1\n",
        "            # label = 0\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n",
        "\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "CelebA_dataset_train = CelebADataset(annotations_file=\"/content/drive/MyDrive/Colab Notebooks/CelebA_Project/archive/list_attr_celeba.csv\",\n",
        "                               img_dir=\"/content/drive/MyDrive/Colab Notebooks/CelebA_Project/archive/img_align_celeba/img_align_celeba\", transform=transform, validation=False)\n",
        "CelebA_dataset_validation = CelebADataset(annotations_file=\"/content/drive/MyDrive/Colab Notebooks/CelebA_Project/archive/list_attr_celeba.csv\",\n",
        "                               img_dir=\"/content/drive/MyDrive/Colab Notebooks/CelebA_Project/archive/img_align_celeba/img_align_celeba\", transform=transform, validation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJuJ8U0gYA0u",
        "outputId": "d2226a84-8022-447c-c817-d8c0150a987b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "trainloader = DataLoader(CelebA_dataset_train, batch_size=64, shuffle=True, num_workers=4)\n",
        "validloader = DataLoader(CelebA_dataset_validation, batch_size=64, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WhvHq4S-Sgrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caace389-0e40-428e-b5e5-c98d393a18b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8000\n"
          ]
        }
      ],
      "source": [
        "print(CelebA_dataset_train.__len__())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ibFDoD82H5h-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd7a35e-c1fe-4381-8e06-29dc3355e8be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[0.8902, 0.8902, 0.8902,  ..., 0.8824, 0.8784, 0.8784],\n",
            "         [0.8902, 0.8902, 0.8902,  ..., 0.8941, 0.8784, 0.8784],\n",
            "         [0.8902, 0.8902, 0.8902,  ..., 0.8824, 0.8745, 0.8745],\n",
            "         ...,\n",
            "         [0.2000, 0.2000, 0.2000,  ..., 0.2431, 0.2431, 0.2431],\n",
            "         [0.2000, 0.2000, 0.2000,  ..., 0.2431, 0.2471, 0.2471],\n",
            "         [0.2000, 0.2000, 0.2000,  ..., 0.2431, 0.2471, 0.2471]],\n",
            "\n",
            "        [[0.8902, 0.8902, 0.8902,  ..., 0.8941, 0.8824, 0.8824],\n",
            "         [0.8902, 0.8902, 0.8902,  ..., 0.9059, 0.8824, 0.8824],\n",
            "         [0.8902, 0.8902, 0.8902,  ..., 0.8941, 0.8784, 0.8784],\n",
            "         ...,\n",
            "         [0.1961, 0.1961, 0.1961,  ..., 0.2392, 0.2392, 0.2392],\n",
            "         [0.1961, 0.1961, 0.1961,  ..., 0.2392, 0.2431, 0.2431],\n",
            "         [0.1961, 0.1961, 0.1961,  ..., 0.2392, 0.2431, 0.2431]],\n",
            "\n",
            "        [[0.8824, 0.8824, 0.8824,  ..., 0.8667, 0.8588, 0.8588],\n",
            "         [0.8824, 0.8824, 0.8824,  ..., 0.8784, 0.8588, 0.8588],\n",
            "         [0.8824, 0.8824, 0.8824,  ..., 0.8667, 0.8549, 0.8549],\n",
            "         ...,\n",
            "         [0.2157, 0.2157, 0.2157,  ..., 0.2588, 0.2627, 0.2627],\n",
            "         [0.2157, 0.2157, 0.2157,  ..., 0.2588, 0.2667, 0.2667],\n",
            "         [0.2157, 0.2157, 0.2157,  ..., 0.2588, 0.2667, 0.2667]]]), 1)\n"
          ]
        }
      ],
      "source": [
        "print(CelebA_dataset_train.__getitem__(7000))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI-v87diAbip",
        "outputId": "87803f49-da63-410e-cd5b-3adc8ffca4ce"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f01110d2fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7FPMFW3gmuK"
      },
      "source": [
        "Inlocuirea ultimului layer din modelul importat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TYyVsmOqczPU"
      },
      "outputs": [],
      "source": [
        "# presupunem ca am creat deja dataset-ul/dataloader-ul\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #(nesterov momentum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2uzrY16re3U4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82489cdc-ee7f-4bfe-a0b5-bedd60a567b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "125it [00:37,  3.36it/s]\n",
            "32it [00:06,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 0.497\n",
            "Accuracy is  tensor(0.7412, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "125it [00:36,  3.41it/s]\n",
            "32it [00:06,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2] loss: 0.499\n",
            "Accuracy is  tensor(0.7432, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "125it [00:36,  3.38it/s]\n",
            "32it [00:06,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3] loss: 0.499\n",
            "Accuracy is  tensor(0.7441, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "125it [00:36,  3.38it/s]\n",
            "32it [00:06,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4] loss: 0.497\n",
            "Accuracy is  tensor(0.7456, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "125it [00:37,  3.36it/s]\n",
            "32it [00:06,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5] loss: 0.499\n",
            "Accuracy is  tensor(0.7446, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "125it [00:37,  3.32it/s]\n",
            "32it [00:06,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6] loss: 0.498\n",
            "Accuracy is  tensor(0.7451, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "125it [00:37,  3.37it/s]\n",
            "32it [00:06,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7] loss: 0.499\n",
            "Accuracy is  tensor(0.7432, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "125it [00:37,  3.36it/s]\n",
            "32it [00:06,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8] loss: 0.501\n",
            "Accuracy is  tensor(0.7422, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "125it [00:37,  3.36it/s]\n",
            "32it [00:06,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9] loss: 0.501\n",
            "Accuracy is  tensor(0.7422, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "125it [00:37,  3.36it/s]\n",
            "32it [00:06,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10] loss: 0.500\n",
            "Accuracy is  tensor(0.7432, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "52it [00:15,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-6e016470fc6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/regnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrunk_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/regnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the network\n",
        "\n",
        "from time import time\n",
        "from tqdm import tqdm \n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Colab Notebooks/CelebA_Project/checkpoint_experiment1\"\n",
        "if os.path.isdir(checkpoint_dir) == False:\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "steps_to_checkpoint = 50\n",
        "\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for i, data in tqdm(enumerate(trainloader, 0)):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)        \n",
        "        loss.backward()        \n",
        "        optimizer.step()\n",
        "        #end = time()\n",
        "        #print(\"We spent \", end - start, \"on fwd+bwd the data\")\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
        "            running_loss = 0.0\n",
        "        if i % steps_to_checkpoint == 49:\n",
        "            torch.save(model.state_dict(), os.path.join(checkpoint_dir, \"model_step_\" + str(i) + \"_epoch_\" + str(epoch) + \".pth\"))\n",
        "        \n",
        "    model.eval() # opresc orice actualizare de parametri\n",
        "    running_loss = 0\n",
        "    corrects = 0\n",
        "    for j, data in tqdm(enumerate(validloader, 0)):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        with torch.no_grad():\n",
        "          outputs = model(inputs)\n",
        "          prob_outputs = nn.Softmax(dim=-1)(outputs)\n",
        "        predicted_labels = torch.argmax(prob_outputs, dim=1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        corrects += torch.sum(predicted_labels == labels)\n",
        "    print(f'[{epoch + 1}] loss: {running_loss / (j+1):.3f}')\n",
        "    print(\"Accuracy is \", corrects / ((j+1)*64))\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inferenta"
      ],
      "metadata": {
        "id": "BlxBsPTtR9ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_model = \"/content/drive/MyDrive/Colab Notebooks/CelebA_Project/checkpoint_experiment1/model_step_49_epoch_5.pth\"\n",
        "\n",
        "model = regnet_y_400mf(weights='IMAGENET1K_V1', )\n",
        "model.fc = torch.nn.Linear(in_features=440, out_features=2, bias=True)\n",
        "model.load_state_dict(torch.load(checkpoint_model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PATwKsjIAwt",
        "outputId": "43b4f305-69fd-4a7d-86bc-e0985a05cca8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "model.to(device)\n",
        "running_loss = 0\n",
        "corrects = 0\n",
        "    \n",
        "for j, data in tqdm(enumerate(validloader, 0)):\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    with torch.no_grad():\n",
        "      outputs = model(inputs)\n",
        "      prob_outputs = nn.Softmax(dim=-1)(outputs)\n",
        "    predicted_labels = torch.argmax(prob_outputs, dim=1)\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss += loss.item()\n",
        "    corrects += torch.sum(predicted_labels == labels)\n",
        "print(f'[{epoch + 1}] loss: {running_loss / (j+1):.3f}')\n",
        "print(\"Accuracy is \", corrects / ((j+1)*64))\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBxJsxF2M6rW",
        "outputId": "88360fe4-e1a7-45f7-8689-ca61a2967371"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "32it [00:06,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11] loss: 0.502\n",
            "Accuracy is  tensor(0.7441, device='cuda:0')\n",
            "Finished Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kwvUzRRsWot9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}